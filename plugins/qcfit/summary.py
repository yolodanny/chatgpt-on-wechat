import openai
import requests
from bs4 import BeautifulSoup
from config import conf
import asyncio 
from pyppeteer import launch

NOT_SUPPORT = 0
BROWSER = 1
DIRECT = 2


class QcSummary:
    def __init__(self):
        openai.api_key  = conf().get("open_ai_api_key")
        pass

    async def summary_url_with_browser(self, url: str, selector: str):
        browser = await launch(
           handleSIGINT=False,
           handleSIGTERM=False,
           handleSIGHUP=False,
           dumpio=True,
           args=['--no-sandbox']
        )
        page = await browser.newPage()
        await page.goto(url)

        if selector:
            await page.waitForSelector(selector)

        content = await page.content()
        await browser.close()
        return content
    
    def run_summary_url_with_browser(self, url, selector):
        loop = asyncio.new_event_loop()  # åˆ›å»ºä¸€ä¸ªæ–°çš„äº‹ä»¶å¾ªç¯
        asyncio.set_event_loop(loop)     # å°†å…¶è®¾ç½®ä¸ºå½“å‰çº¿ç¨‹çš„äº‹ä»¶å¾ªç¯
        content = loop.run_until_complete(self.summary_url_with_browser(url, selector))
        soup = BeautifulSoup(content, 'html.parser')

        webpage_text = soup.get_text().replace(" ", "").replace("\t", "").replace("\n", "")
        print(webpage_text)
        return webpage_text

    def summary_url(self, url: str):
        check_browser_result = self.check_browser_url(url)
        if check_browser_result[0] == BROWSER:
            webpage_text = self.run_summary_url_with_browser(url, check_browser_result[1])
        elif check_browser_result[0] == DIRECT:
            webpage_text = self.get_webpage_text(url)
        else:
            return "å“å‘€ï¼Œæˆ‘å¥½åƒæ— æ³•æ‰“å¼€è¿™ç¯‡æ–‡ç« ï¼Œè¯·æ¢ä¸€ç¯‡æ–‡ç« è¯•è¯•å§~"
        
        try:
            max_chunk_length = 2048  # æ ¹æ®ChatGPTæ¨¡å‹çš„æœ€å¤§é•¿åº¦æ¥è®¾ç½®
            text_chunks = self.split_text_into_chunks(webpage_text, max_chunk_length)
            simplify_chunks = []

            if len(text_chunks) == 1:
                print("====== å¼€å§‹æ€»ç»“ ======")
                final_summary = self.summary_content(text_chunks[0].replace("\n", ""))
            else:
                print("===== å¼€å§‹åˆ†æ®µå¤„ç† =====")
                for chunk in text_chunks:
                    simplify_chunks.append(self.simplify_content(chunk.replace("\n", "")))
            
                print("====== å¼€å§‹æ€»ç»“ ======")
                final_summary = self.summary_content(" ".join(simplify_chunks))
        except:
            return "æœªçŸ¥é”™è¯¯ï¼Œè¯·é‡è¯•"
        else:
            return final_summary   

    def get_completion(self, prompt, model="gpt-3.5-turbo"):
        messages = [{"role": "user", "content": prompt}]
        response = openai.ChatCompletion.create(
            model=model,
            messages=messages,
            temperature=0.6, # this is the degree of randomness of the model's output
        )
        return response.choices[0].message["content"]

    def simplify_content(self, text):
        prompt = f"""
        ä¿æŒå†…å®¹å«ä¹‰ä»¥åŠä¹¦å†™é£æ ¼ä¸å˜çš„æƒ…å†µä¸‹ï¼Œç”¨ä¸è¶…è¿‡400ä¸ªå­—ç®€å†™```ä¹‹é—´çš„å†…å®¹
        ```{text}```
        """

        return self.get_completion(prompt)

    def summary_content(self, text):
        prompt = f"""
        è¯·å¯¹```ä¸­çš„å†…å®¹Sï¼Œå®Œæˆä»¥ä¸‹æ“ä½œã€‚
        ç¬¬ä¸€æ­¥ï¼Œä»Sçš„å†…å®¹ä¸­æå–æœ€å¤š5æ¡å…³é”®å†…å®¹ï¼Œæ¯ä¸ªä¸ºä¸€å¥è¯ï¼Œå­˜å‚¨ä¸ºY1,Y2...Yn
        ç¬¬äºŒæ­¥ï¼Œæ ¹æ®ç¬¬ä¸€æ­¥æ€»ç»“å‡ºæ¥çš„å…³é”®å†…å®¹ï¼Œæç‚¼å‡ºä¸€ä¸ªæ ‡é¢˜ï¼Œå­˜å‚¨ä¸ºX
        ç¬¬ä¸‰æ­¥ï¼Œä»Sçš„å†…å®¹ä¸­æå–åšå¤š3ä¸ªæ ‡ç­¾ï¼Œå­˜å‚¨ä¸ºT1,T2..Tn

        è¾“å‡ºå†…å®¹ï¼Œè¾“å‡ºæ ¼å¼ä¸º
        ğŸ“– ä¸€å¥è¯æ€»ç»“: X
        
        ğŸ”‘ å…³é”®è¦ç‚¹ï¼š 
            1.Y1
            ...
            n.Yn

        ğŸ· æ ‡ç­¾ï¼š #T1...#Tn
        ```{text}```
        """

        return self.get_completion(prompt)

    def split_text_into_chunks(self, text, max_chunk_length):
        chunks = []
        start = 0

        while start < len(text):
            end = start + max_chunk_length
            chunks.append(text[start:end])
            start = end

        return chunks

    def get_webpage_text(self, url: str):
      try:
          response = requests.get(url)
          response.raise_for_status()  # æ£€æŸ¥æ˜¯å¦å‘ç”Ÿé”™è¯¯

          soup = BeautifulSoup(response.content, 'html.parser')

          webpage_text = soup.get_text().replace(" ", "").replace("\t", "").replace("\n", "")
          return webpage_text
      except Exception as e:
          print(f"Error occurred while fetching the webpage: {e}")
          return None
      
    def check_browser_url(self, url: str):
        black_list = ["https://me.mbd.baidu.com"]
        tt_list = ["https://www.toutiao.com", "https://m.toutiao.com"]
        bd_list = ["https://mbd.baidu.com/"]

        for support_url in black_list:
            if url.strip().startswith(support_url):
                return [NOT_SUPPORT, '']

        for support_url in tt_list:
            if url.strip().startswith(support_url):
                return [BROWSER, 'h1']
        for support_url in bd_list:
            if url.strip().startswith(support_url):
                return [BROWSER, '']
            
        return [DIRECT, '']
